{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.BGGM Plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Networks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import imageio\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "critical_date=pd.to_datetime(['2013-01-01','2014-10-30','2015-12-17','2019-08-01','2021-11-04','2023-06-01'])\n",
    "\n",
    "# Categories for developed and emerging countries\n",
    "developed_countries = ['AUS', 'CAN', 'FRA', 'GER', 'JPN', 'SIN', 'UK', 'US']\n",
    "emerging_countries = ['ARG', 'BRA', 'CHN', 'IND', 'KOR', 'MEX', 'RUS', 'THA']\n",
    "\n",
    "# diction\n",
    "country_code_to_name = {\n",
    "    'AUS': 'Australia',\n",
    "    'CAN': 'Canada',\n",
    "    'FRA': 'France',\n",
    "    'GER': 'Germany',\n",
    "    'JPN': 'Japan',\n",
    "    'UK': 'UK',\n",
    "    'US': 'US',\n",
    "    'ARG': 'Argentina',\n",
    "    'BRA': 'Brazil',\n",
    "    'CHN': 'China',\n",
    "    'IND': 'India',\n",
    "    'KOR': 'Korea',\n",
    "    'MEX': 'Mexico',\n",
    "    'RUS': 'Russia',\n",
    "    'SIN': 'Singapore',\n",
    "    'THA': 'Thailand'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for mkt in ['composite','bond', 'forex', 'stock', 'gold']:\n",
    "\n",
    "    image_frames = []\n",
    "\n",
    "    path = f'DataAnalysis\\\\BGGM Analysis\\\\BGGMnetworks\\\\{mkt}'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    gif_path = path\n",
    "    node_impact_pd=pd.DataFrame()\n",
    "    #df_market=pd.read_csv('ctg_market\\\\'+mkt+'_Market.csv')\n",
    "    df_market=pd.read_csv(f'DataAnalysis\\\\CTG Analysis\\\\summed_ctg_index\\\\{mkt}_Market.csv')\n",
    "    df_market['date'] = pd.to_datetime(df_market['date'])\n",
    "\n",
    "\n",
    "    for k in range(5):\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(f'Data\\BGGM\\pcorr_{mkt}\\\\pcorr_{k+1}.csv')\n",
    "        df.set_index('Unnamed: 0', inplace=True)\n",
    "\n",
    "        # Create an empty graph\n",
    "        G = nx.Graph()\n",
    "\n",
    "        # Add nodes to the graph\n",
    "        for country in developed_countries:\n",
    "            G.add_node(country, category='developed')\n",
    "        for country in emerging_countries:\n",
    "            G.add_node(country, category='emerging')\n",
    "\n",
    "        # Add edges to the graph based on the DataFrame\n",
    "        for i, row in df.iterrows():\n",
    "            for j, cell in row.items():\n",
    "                if i != j and cell != 0:  # Exclude self-loops and zero weights\n",
    "                    color = 'green' if cell > 0 else 'orange'\n",
    "                    G.add_edge(i, j, weight=abs(cell), color=color)\n",
    "\n",
    "        # Calculate the positions\n",
    "        n = len(G.nodes)\n",
    "        angle = np.linspace(0, 2*np.pi, n, endpoint=False)\n",
    "        sorted_nodes = developed_countries + [node for node in G.nodes if node not in developed_countries]\n",
    "        pos = {}\n",
    "        for idx, node in enumerate(sorted_nodes):\n",
    "            pos[node] = (np.cos(angle[idx]+np.pi/n), np.sin(angle[idx]+np.pi/n))\n",
    "\n",
    "        nodes=list(G.nodes)\n",
    "\n",
    "        # Calculate the node impact\n",
    "        node_impact = {node: 0 for node in nodes}\n",
    "        node_impact\n",
    "\n",
    "        current_start_date = critical_date[k]\n",
    "        current_end_date = critical_date[k+1]\n",
    "        print(f\"Analyzing BGGM Network from {current_start_date.date()} to {current_end_date.date()}\")\n",
    "\n",
    "        # Add edges and attributes, update node sizes\n",
    "        for node in nodes:\n",
    "            df_filtered = df_market[(df_market['date'] >= pd.Timestamp(current_start_date.date())) & (df_market['date'] < pd.Timestamp(current_end_date.date()))]\n",
    "            node_impact[node] = np.average(df_filtered[node].dropna())\n",
    "\n",
    "        node_impact_pd[f'{current_start_date.date()}-{current_end_date.date()}']=pd.Series(node_impact)\n",
    "\n",
    "\n",
    "        # Calculate node sizes proportional to their impact\n",
    "        total_impact = sum(node_impact.values())\n",
    "        #print(total_impact)\n",
    "        alpha = 1000 if mkt=='composite' else 4000\n",
    "        node_sizes = {node: (impact ) * alpha for node, impact in node_impact.items()}\n",
    "\n",
    "\n",
    "        # Set up plot with a white background\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.set_facecolor('white')\n",
    "        plt.axis('off')\n",
    "        ax.set_aspect('equal', 'box')\n",
    "\n",
    "        # Draw the graph\n",
    "        node_colors = ['blue' if node in developed_countries else 'red' for node in G.nodes()]\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=[node_sizes[node] for node in G.nodes()],)  # Increased node size to 500\n",
    "        edges = G.edges()\n",
    "        edge_colors = [G[u][v]['color'] for u, v in edges]\n",
    "        edge_weights = [G[u][v]['weight'] * 10 for u, v in edges]\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color=edge_colors, width=edge_weights)\n",
    "        nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "        # Show the plot\n",
    "        #plt.title('Modified Network of Partial Correlations between Countries')\n",
    "        plt.tight_layout()\n",
    "        tmp_image_path = gif_path+f\"\\\\BGGM_Network_from_{current_start_date.date()}_to_{current_end_date.date()}.png\"\n",
    "        plt.savefig(tmp_image_path, facecolor='white', dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Append the image to the list of image frames\n",
    "        image_frames.append(imageio.imread(tmp_image_path))\n",
    "\n",
    "\n",
    "    # Create the GIF using the list of image frames\n",
    "    #imageio.mimsave(gif_path+f'\\BGGM_network.gif', image_frames, duration=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Heatmaps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "for mkt in ['composite','bond', 'forex', 'stock', 'gold']:\n",
    "\n",
    "    image_frames = []\n",
    "\n",
    "    for i in range(1,6):\n",
    "\n",
    "        #if not os.path.exists(f'pcorr\\\\tables\\\\pcorr_{i}.csv'):\n",
    "        #    print(f\"File does not exist: pcorr_{i}.csv\")\n",
    "        #    continue\n",
    "\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(f'Data\\\\BGGM\\\\pcorr_'+mkt+f'\\\\pcorr_{i}.csv')\n",
    "\n",
    "        # Define the list of developed and developing countries based on their UN codes in the dataset\n",
    "        developed_countries = ['AUS', 'CAN', 'FRA', 'GER', 'JPN', 'SIN', 'UK', 'US']\n",
    "        emerging_countries = ['ARG', 'BRA', 'CHN', 'IND', 'KOR', 'MEX', 'RUS', 'THA']\n",
    "\n",
    "        # Combine the two lists to form the new order\n",
    "        new_order = developed_countries + emerging_countries\n",
    "\n",
    "        # Reorder the DataFrame according to the new list\n",
    "        df_reorder = df.set_index('Unnamed: 0').loc[new_order, new_order].reset_index()\n",
    "\n",
    "        # Modify the DataFrame to set the diagonal values to 1\n",
    "        df_reorder_modified = df_reorder.set_index('Unnamed: 0')\n",
    "        for country in df_reorder_modified.index:\n",
    "            df_reorder_modified.at[country, country] = 1\n",
    "\n",
    "        # Setting up the plot style\n",
    "        sns.set(style=\"white\")\n",
    "\n",
    "        # Create the heatmap with the reordered DataFrame\n",
    "        plt.figure(figsize=(14, 12))\n",
    "        heatmap = sns.heatmap(df_reorder_modified, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, linewidths=.5, cbar_kws={\"shrink\": .75}, vmin=-1, vmax=1)\n",
    "\n",
    "        # Add title and labels\n",
    "        #plt.title('Partial Correlation Heatmap')\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()\n",
    "        path = os.getcwd()+f'\\\\DataAnalysis\\\\BGGM Analysis\\\\BGGMheatmaps\\\\{mkt}'\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        tmp_image_path=path+f'\\\\heatmap_{i}.png'\n",
    "        plt.savefig(tmp_image_path,dpi=300)\n",
    "        plt.close()\n",
    "        #plt.show()\n",
    "\n",
    "        # Append the image to the list of image frames\n",
    "        #image_frames.append(imageio.imread(tmp_image_path))\n",
    "\n",
    "\n",
    "    # Create the GIF using the list of image frames\n",
    "    #imageio.mimsave(f'pcorr\\heatmaps\\heatmap.gif', image_frames, duration=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Statistical Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Developed Countries v.s. Emerging countries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define developed and emerging countries\n",
    "developed_countries = ['AUS', 'CAN', 'FRA', 'GER', 'JPN', 'SIN', 'UK', 'US']\n",
    "emerging_countries = ['ARG', 'BRA', 'CHN', 'IND', 'KOR', 'MEX', 'RUS', 'THA']\n",
    "\n",
    "for mkt in ['composite','bond', 'forex', 'stock', 'gold']:\n",
    "\n",
    "    result=[]\n",
    "\n",
    "    for k in range(1,6):\n",
    "\n",
    "        # Load the partial correlation matrix from the provided CSV file\n",
    "        file_path = f'Data\\\\BGGM\\\\pcorr_'+mkt+f'\\\\pcorr_{k}.csv'\n",
    "        pcorr_df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "        # Initialize counts for each category\n",
    "        count_pos_developed, count_neg_developed, count_zero_developed = 0, 0, 0\n",
    "        count_pos_mixed, count_neg_mixed, count_zero_mixed = 0, 0, 0\n",
    "        count_pos_emerging, count_neg_emerging, count_zero_emerging = 0, 0, 0\n",
    "\n",
    "        # Loop through the matrix to count positive, negative, and zero values\n",
    "        for i, country1 in enumerate(pcorr_df.index):\n",
    "            for j, country2 in enumerate(pcorr_df.columns):\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                value = pcorr_df.at[country1, country2]\n",
    "\n",
    "                # Developed-developed\n",
    "                if country1 in developed_countries and country2 in developed_countries:\n",
    "                    count_pos_developed += (value > 0)\n",
    "                    count_neg_developed += (value < 0)\n",
    "                    count_zero_developed += (value == 0)\n",
    "\n",
    "                # Developed-emerging\n",
    "                elif (country1 in developed_countries and country2 in emerging_countries) or \\\n",
    "                     (country1 in emerging_countries and country2 in developed_countries):\n",
    "                    count_pos_mixed += (value > 0)\n",
    "                    count_neg_mixed += (value < 0)\n",
    "                    count_zero_mixed += (value == 0)\n",
    "\n",
    "                # Emerging-emerging\n",
    "                elif country1 in emerging_countries and country2 in emerging_countries:\n",
    "                    count_pos_emerging += (value > 0)\n",
    "                    count_neg_emerging += (value < 0)\n",
    "                    count_zero_emerging += (value == 0)\n",
    "\n",
    "        # Calculate proportions\n",
    "        total_developed = count_pos_developed + count_neg_developed + count_zero_developed\n",
    "        total_mixed = count_pos_mixed + count_neg_mixed + count_zero_mixed\n",
    "        total_emerging = count_pos_emerging + count_neg_emerging + count_zero_emerging\n",
    "\n",
    "        prop_pos_developed = count_pos_developed / total_developed\n",
    "        prop_neg_developed = count_neg_developed / total_developed\n",
    "        prop_zero_developed = count_zero_developed / total_developed\n",
    "\n",
    "        prop_pos_mixed = count_pos_mixed / total_mixed\n",
    "        prop_neg_mixed = count_neg_mixed / total_mixed\n",
    "        prop_zero_mixed = count_zero_mixed / total_mixed\n",
    "\n",
    "        prop_pos_emerging = count_pos_emerging / total_emerging\n",
    "        prop_neg_emerging = count_neg_emerging / total_emerging\n",
    "        prop_zero_emerging = count_zero_emerging / total_emerging\n",
    "\n",
    "        # Create a results dictionary\n",
    "        results_dict = {\n",
    "            'Phase': f'{k}',\n",
    "            'DD_Positive': prop_pos_developed, 'DD_Negative': prop_neg_developed, 'DD_Zero': prop_zero_developed,\n",
    "            'DE_Positive': prop_pos_mixed, 'DE_Negative': prop_neg_mixed, 'DE_Zero': prop_zero_mixed,\n",
    "            'EE_Positive': prop_pos_emerging, 'EE_Negative': prop_neg_emerging, 'EE_Zero': prop_zero_emerging,\n",
    "        }\n",
    "\n",
    "        result.append(results_dict)\n",
    "\n",
    "    result_pd=pd.DataFrame(result).set_index('Phase')\n",
    "    result_pd.to_csv(f'DataAnalysis\\\\BGGM Analysis\\\\StatisticalAnalysis\\\\developed_emerging_analysis\\\\{mkt}.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Measurement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CDC & CDI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# Define your critical dates\n",
    "critical_date = ['2013-01-01', '2014-10-30', '2015-12-17', '2019-08-01', '2021-11-04', '2023-06-01']\n",
    "\n",
    "# Initialize DataFrames to store the results\n",
    "average_degrees = pd.DataFrame(index=[f'phase {i}' for i in range(1, len(critical_date))], columns=['composite','bond', 'forex', 'stock', 'gold'])\n",
    "average_weights = pd.DataFrame(index=[f'phase {i}' for i in range(1, len(critical_date))], columns=['composite','bond', 'forex', 'stock', 'gold'])\n",
    "\n",
    "# Loop over each market and phase\n",
    "for mkt in ['composite','bond', 'forex', 'stock', 'gold']:\n",
    "    for i in range(1, len(critical_date)):\n",
    "        # Step 1: Load the CSV Data into a DataFrame\n",
    "        try:\n",
    "            df_pcorr = pd.read_csv(f'Data\\\\BGGM\\\\pcorr_'+mkt+f'\\\\pcorr_{i}.csv', index_col=0)\n",
    "\n",
    "            # Step 2: Create a Graph\n",
    "            G = nx.Graph()\n",
    "\n",
    "            # Step 3: Add Edges to the Graph\n",
    "            for idx, row in df_pcorr.iterrows():\n",
    "                for col, cell in row.items():\n",
    "                    if idx != col and cell != 0:  # Exclude self-loops and zero values\n",
    "                        G.add_edge(idx, col, weight=abs(cell))\n",
    "\n",
    "            # Step 4: Calculate the Average Degree\n",
    "            average_degree = sum(dict(G.degree()).values()) / 16 #G.number_of_nodes()\n",
    "\n",
    "            # Step 5: Calculate the Average Weight of Non-Zero Edges\n",
    "            edge_weights = [data['weight'] for _, _, data in G.edges(data=True)]\n",
    "            average_edge_weight = sum(edge_weights) / len(edge_weights) if edge_weights else 0\n",
    "\n",
    "            # Store the results in the respective DataFrames\n",
    "            average_degrees.at[f'phase {i}', mkt] = average_degree\n",
    "            average_weights.at[f'phase {i}', mkt] = average_edge_weight\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File for market '{mkt}' and phase '{i}' not found.\")\n",
    "\n",
    "# Output the DataFrames\n",
    "average_degrees.to_csv('DataAnalysis\\BGGM Analysis\\StatisticalAnalysis\\Measurements\\closeness.csv')\n",
    "average_weights.to_csv('DataAnalysis\\BGGM Analysis\\StatisticalAnalysis\\Measurements\\intensity.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SSP & SST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "critical_date = pd.to_datetime(['2013-01-01', '2014-10-30', '2015-12-17', '2019-08-01', '2021-11-04', '2023-06-01'])\n",
    "\n",
    "\n",
    "# Loop over each market and phase\n",
    "for mkt in ['composite','bond', 'forex', 'stock', 'gold']:\n",
    "    # Load the market data\n",
    "    df_market = pd.read_csv('DataAnalysis\\\\CTG Analysis\\\\summed_ctg_index\\\\'+mkt+'_Market.csv')\n",
    "    df_market['date'] = pd.to_datetime(df_market['date'])\n",
    "\n",
    "    # Define nodes and critical dates\n",
    "    nodes = df_market.columns[1:].tolist()\n",
    "\n",
    "\n",
    "    # Initialize an empty DataFrame to store node impact\n",
    "    node_impact_pd = pd.DataFrame()\n",
    "\n",
    "    # Calculate node impact for each phase\n",
    "    for k in range(5):\n",
    "        node_impact = {node: 0 for node in nodes}\n",
    "        current_start_date = critical_date[k]\n",
    "        current_end_date = critical_date[k + 1]\n",
    "        for node in nodes:\n",
    "            df_filtered = df_market[(df_market['date'] >= current_start_date) & (df_market['date'] < current_end_date)]\n",
    "            node_impact[node] = np.average(df_filtered[node].dropna())\n",
    "        node_impact_pd[f'phase{k + 1}'] = pd.Series(node_impact)\n",
    "\n",
    "    # Load the partial correlation data for each phase\n",
    "    #pcorr_files = [f'pcorr_{i + 1}.csv' for i in range(5)]\n",
    "    #pcorr_dfs = [pd.read_csv(file).set_index('Unnamed: 0') for file in pcorr_files]\n",
    "\n",
    "    # Initialize DataFrames to store Spillover and Stability Measurements\n",
    "    spillover_df = pd.DataFrame(index=nodes)\n",
    "    stability_df = pd.DataFrame(index=nodes)\n",
    "\n",
    "    # Calculate Spillover and Stability Measurements for each phase with corrected total node impact\n",
    "    for k in range(5):\n",
    "\n",
    "        pcorr_df=pd.read_csv(f'Data\\BGGM\\pcorr_{mkt}\\\\pcorr_{k+1}.csv').set_index('Unnamed: 0')\n",
    "\n",
    "        spillover_values = {}\n",
    "        stability_values = {}\n",
    "        node_impact_phase = node_impact_pd[f'phase{k + 1}']\n",
    "        total_node_impact_current_phase = node_impact_phase.sum()\n",
    "        for node in nodes:\n",
    "            pos_corr = pcorr_df.loc[node][pcorr_df.loc[node] > 0]\n",
    "            neg_corr = pcorr_df.loc[node][pcorr_df.loc[node] < 0]\n",
    "            spillover = (pos_corr * (node_impact_phase[node] + node_impact_phase[pos_corr.index])).sum() / total_node_impact_current_phase\n",
    "            stability = (abs(neg_corr) * (node_impact_phase[node] + node_impact_phase[neg_corr.index])).sum() / total_node_impact_current_phase\n",
    "            spillover_values[node] = spillover\n",
    "            stability_values[node] = stability\n",
    "        spillover_df[f'phase{k + 1}'] = pd.Series(spillover_values)\n",
    "        stability_df[f'phase{k + 1}'] = pd.Series(stability_values)\n",
    "\n",
    "    # Save the DataFrames to CSV files\n",
    "    spillover_df.to_csv(f'DataAnalysis\\\\BGGM Analysis\\\\StatisticalAnalysis\\\\Measurements\\\\Spillover_Measurements_{mkt}.csv')\n",
    "    stability_df.to_csv(f'DataAnalysis\\\\BGGM Analysis\\\\StatisticalAnalysis\\\\Measurements\\\\Stability_Measurements_{mkt}.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
